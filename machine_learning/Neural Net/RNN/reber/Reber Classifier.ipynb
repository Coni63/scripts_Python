{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REBER Grammar with RNN\n",
    "\n",
    "This workbook follows the notebook regarding <a href=\"https://www.willamette.edu/~gorr/classes/cs449/reber.html\" target=\"_blank\">Reber's grammar</a> words. In this one we gonna train a classifier to validate Embedded Reber's word\n",
    "\n",
    "## What is a Reber Word ?\n",
    "\n",
    "The embedded version Reber word is a word following the graph:\n",
    "\n",
    "<img src=\"embreber.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "import create_dataset as reber\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, SimpleRNN, GRU, TimeDistributed,Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of datas\n",
    "\n",
    "We discover on the previous notebook how to generate a dataset for the training. We just gonna change it to use Embedded Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBTSSSXXVPSET\n"
     ]
    }
   ],
   "source": [
    "x, y = reber.get_one_embedded_example(minLength=10)\n",
    "print(reber.sequenceToWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reber.in_grammar(reber.sequenceToWord(x)[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      "BTBTSSSXXVPSET\n"
     ]
    }
   ],
   "source": [
    "print(reber.get_char_one_hot(\"B\"))\n",
    "print(reber.sequenceToWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPBPTVPXVPXTVPSEP\n",
      "BPBPXVPXVPXTVPSEP\n"
     ]
    }
   ],
   "source": [
    "def set_wrong(good_seq):\n",
    "    index = np.random.randint(len(good_seq))\n",
    "    letter = reber.sequenceToWord([good_seq[index]])\n",
    "    new_letter = random.choice(list(set(\"BTSXPVE\") - set(letter)))\n",
    "    bad_seq = good_seq.copy()\n",
    "    bad_seq[index] = np.array(reber.get_char_one_hot(new_letter)[0])\n",
    "    return bad_seq\n",
    "\n",
    "x, y = reber.get_one_embedded_example(minLength=10)\n",
    "print(reber.sequenceToWord(x))\n",
    "x2 = set_wrong(x)\n",
    "print(reber.sequenceToWord(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the target, we can reuse the previous fonction to generate the output based on the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's build our dataset. Due to the embedding features, the maxlen for the padding will be increase to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 7)\n",
      "(1000, 30, 1)\n",
      "(200, 30, 7)\n",
      "(200, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30\n",
    "min_length = 10\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "X_val, y_val = [], []\n",
    "y_possible = []\n",
    "\n",
    "for i in range(1000):\n",
    "    x, y = reber.get_one_embedded_example(minLength=min_length)\n",
    "    res = [[1]]*30\n",
    "    if random.random() < 0.5:\n",
    "        x = set_wrong(x)\n",
    "        res = [[0]]*30\n",
    "    X_train.append(x)\n",
    "    y_train.append(res)\n",
    "\n",
    "for i in range(200):\n",
    "    x, y = reber.get_one_embedded_example(minLength=min_length)\n",
    "    res = [[1]]*30\n",
    "    if random.random() < 0.5:\n",
    "        x = set_wrong(x)\n",
    "        res = [[0]]*30\n",
    "    X_test.append(x)\n",
    "    y_test.append(res)  \n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "#y_train = sequence.pad_sequences(y_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "#y_test = sequence.pad_sequences(y_test, maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]\n",
      " [96]]\n"
     ]
    }
   ],
   "source": [
    "#print(y_test)\n",
    "print(np.sum(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we found out that the GRU performed really better than LSTM and SimpleRNN. As a result we will focus on this model to improve it to generate correct sequences\n",
    "\n",
    "## Test on GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the writing of this notebook, I tried some loss, metrics and optimizer. The following ones are the one fitting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unit = 7\n",
    "inp_shape = (maxlen, 7)\n",
    "loss_ = \"mean_squared_error\"\n",
    "metrics_ = \"mean_squared_error\"\n",
    "optimizer_ = \"Nadam\"\n",
    "nb_epoch = 1000\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=nb_unit, input_shape=inp_shape, return_sequences=True))  # single LSTM\n",
    "model.add(TimeDistributed(Dense(1), input_shape=inp_shape))\n",
    "model.compile(loss=loss_, optimizer=optimizer_, metrics=[metrics_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (None, 30, 7)\n",
      "Outputs: (None, 30, 1)\n",
      "Actual input: (1000, 30, 7)\n",
      "Actual output: (1000, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print(\"Outputs: {}\".format(model.output_shape))\n",
    "print(\"Actual input: {}\".format(X_train.shape))\n",
    "print(\"Actual output: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 2s - loss: 0.4212 - mean_squared_error: 0.4212 - val_loss: 0.3769 - val_mean_squared_error: 0.3769\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.4013 - mean_squared_error: 0.4013 - val_loss: 0.3628 - val_mean_squared_error: 0.3628\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.3496 - val_mean_squared_error: 0.3496\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3728 - mean_squared_error: 0.3728 - val_loss: 0.3368 - val_mean_squared_error: 0.3368\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.3245 - val_mean_squared_error: 0.3245\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3462 - mean_squared_error: 0.3462 - val_loss: 0.3129 - val_mean_squared_error: 0.3129\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.3023 - val_mean_squared_error: 0.3023\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3221 - mean_squared_error: 0.3221 - val_loss: 0.2928 - val_mean_squared_error: 0.2928\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3116 - mean_squared_error: 0.3116 - val_loss: 0.2846 - val_mean_squared_error: 0.2846\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.3027 - mean_squared_error: 0.3027 - val_loss: 0.2779 - val_mean_squared_error: 0.2779\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2950 - mean_squared_error: 0.2950 - val_loss: 0.2727 - val_mean_squared_error: 0.2727\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2887 - mean_squared_error: 0.2887 - val_loss: 0.2688 - val_mean_squared_error: 0.2688\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2835 - mean_squared_error: 0.2835 - val_loss: 0.2660 - val_mean_squared_error: 0.2660\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2798 - mean_squared_error: 0.2798 - val_loss: 0.2640 - val_mean_squared_error: 0.2640\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2770 - mean_squared_error: 0.2770 - val_loss: 0.2626 - val_mean_squared_error: 0.2626\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2745 - mean_squared_error: 0.2745 - val_loss: 0.2614 - val_mean_squared_error: 0.2614\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2722 - mean_squared_error: 0.2722 - val_loss: 0.2604 - val_mean_squared_error: 0.2604\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2704 - mean_squared_error: 0.2704 - val_loss: 0.2594 - val_mean_squared_error: 0.2594\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2688 - mean_squared_error: 0.2688 - val_loss: 0.2584 - val_mean_squared_error: 0.2584\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s - loss: 0.2673 - mean_squared_error: 0.2673 - val_loss: 0.2575 - val_mean_squared_error: 0.2575\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 7)             420       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 1)             8         \n",
      "=================================================================\n",
      "Total params: 428\n",
      "Trainable params: 428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 4.5619120597839355s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=500)\n",
    "stop = time.time()\n",
    "t = stop-start\n",
    "print(model.summary(), end=\" \")\n",
    "print(\"Training time : {:}s\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.181]\n",
      "  [ 0.322]\n",
      "  [ 0.422]\n",
      "  ..., \n",
      "  [ 0.393]\n",
      "  [ 0.384]\n",
      "  [ 0.376]]\n",
      "\n",
      " [[ 0.181]\n",
      "  [ 0.357]\n",
      "  [ 0.455]\n",
      "  ..., \n",
      "  [ 0.387]\n",
      "  [ 0.379]\n",
      "  [ 0.371]]\n",
      "\n",
      " [[ 0.181]\n",
      "  [ 0.357]\n",
      "  [ 0.455]\n",
      "  ..., \n",
      "  [ 0.357]\n",
      "  [ 0.353]\n",
      "  [ 0.348]]\n",
      "\n",
      " ..., \n",
      " [[ 0.181]\n",
      "  [ 0.357]\n",
      "  [ 0.455]\n",
      "  ..., \n",
      "  [ 0.369]\n",
      "  [ 0.363]\n",
      "  [ 0.357]]\n",
      "\n",
      " [[ 0.181]\n",
      "  [ 0.322]\n",
      "  [ 0.422]\n",
      "  ..., \n",
      "  [ 0.377]\n",
      "  [ 0.369]\n",
      "  [ 0.363]]\n",
      "\n",
      " [[ 0.181]\n",
      "  [ 0.357]\n",
      "  [ 0.455]\n",
      "  ..., \n",
      "  [ 0.375]\n",
      "  [ 0.368]\n",
      "  [ 0.362]]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s     \n",
      "Test score: 0.257494045272\n",
      "Test accuracy: 0.257494045272\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Every models will be evaluated on the fonction designed previously which count on 20 x 100 word generated by the NN, how much are following the rule. But first, let's check if the training is \"over\" by checking the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"GRU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is \"stable\" even if it didn't reached yet the best point. We can also take a look to the output based on the X_val we generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input :\")\n",
    "print(X_val)\n",
    "print(\"\\n\\n Output :\")\n",
    "y_pred = model.predict(X_val)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform the cleaning and compare it to the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred < 0.1, 0, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, real in zip(y_pred[0], y_possible[0]):\n",
    "    print(pred, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output is clearly more \"shuffled\". This model starts to show it's own limit. We can check the output on the generation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_embedded_word(w):\n",
    "    if w[:2] not in [\"BT\", \"BP\"]:\n",
    "        return False\n",
    "    if reber.in_grammar(w[2:-1]):\n",
    "        return False\n",
    "    if w[-1] not in [\"T\", \"P\"]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def Pick_From_Output(x):\n",
    "    y = np.zeros_like(x)\n",
    "    x = np.where(x < 0.1, 0, x)\n",
    "    x = x[0]/x[0].sum(axis=1)\n",
    "    i = np.random.choice(list(range(7)), size=1, p=x[0])\n",
    "    y[0,0,i] = 1\n",
    "    return y\n",
    "\n",
    "def evaluate(model, nb_word = 1, max_iter = 50):\n",
    "    good_pred = 0\n",
    "    for _ in range(nb_word):\n",
    "        model.reset_states()\n",
    "        first_input = np.array([[[1,0,0,0,0,0,0]]])\n",
    "        word = \"B\"\n",
    "        loop = 0\n",
    "        nextLetter = \"B\"\n",
    "        next_seq = first_input\n",
    "        while nextLetter != \"E\" and loop < max_iter:\n",
    "            y_pred = model.predict(next_seq)\n",
    "            next_seq = Pick_From_Output(y_pred)\n",
    "            nextLetter = reber.sequenceToWord(next_seq[0])\n",
    "            loop += 1\n",
    "            word += nextLetter\n",
    "        if is_embedded_word(word):\n",
    "            good_pred += 1\n",
    "    acc = 100*good_pred/nb_word\n",
    "    print(\"Good prediction : {:.2f}%\".format(acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newModel = Sequential()\n",
    "newModel.add(GRU(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True, verbose=0))\n",
    "newModel.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_GRU = []\n",
    "for _ in range(20):\n",
    "    result_GRU.append(evaluate(newModel, 100, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is really worse than it was previously. This is due to the more complexe rule behind the embedded words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(20))\n",
    "y = [result_GRU]\n",
    "labels = [\"GRU\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for y_arr, label in zip(y, labels):\n",
    "    plt.plot(x, y_arr, label=label)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "Now let's do the same but with differents topology and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unit = 7\n",
    "inp_shape = (maxlen, 7)\n",
    "loss_ = \"mean_squared_error\"\n",
    "metrics_ = \"mean_squared_error\"\n",
    "optimizer_ = \"Nadam\"\n",
    "nb_epoch = 1000\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=nb_unit, input_shape=inp_shape, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=nb_unit, return_sequences=True))\n",
    "model.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=nb_epoch, batch_size=batch_size, verbose=0)\n",
    "stop = time.time()\n",
    "t = stop-start\n",
    "print(model.summary(), end=\" \")\n",
    "print(\"Training time : {:}s\".format(t))\n",
    "plt.plot(history.history[\"loss\"], label=\"GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = Sequential()\n",
    "newModel.add(GRU(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.add(GRU(units=nb_unit, return_sequences=True))\n",
    "newModel.set_weights(model.get_weights())\n",
    "\n",
    "result_GRU = []\n",
    "for _ in range(20):\n",
    "    result_GRU.append(evaluate(newModel, 100, 50))\n",
    "\n",
    "plt.plot(list(range(20)), result_GRU)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "IUn this workbook, we started to go through RNN. We check simple model of both LSTM, GRU and SimpleRNN to check how fast and well they learn. On this example GRU outperform other models for 2 reasons:\n",
    "<li>LSTM are better for long sequence memory. On this short example, the generator jumped from a node to another one with the same letter (see red arrow below) <img src=\"reber_jump.png\"/>. In fact, it outputs a too high probability of those non-allowed rules and the \"PickOne\" function had risks to pick it</li>\n",
    "<li>Simple RNN are not strong enougth with 1 hidden layer to \"remember\" all those rules. We need a longer NN which is also longer to train. This simpleRNN is faster but nearly never used anymore as it perform very poorly on lot of cases</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "On a future notebook, we will explore Embedded Reber but using deeper RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
