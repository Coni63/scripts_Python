{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "In this exercice, we are going to do the first Neural Network with Tensorflow. We will explore some models, tweak their topology, activation function and check the impact in Tensorboard. As input we gonna use the mnist dataset included in Tensorflow\n",
    "\n",
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to create the Model. The model will contain :\n",
    "<li>1 input layer of size \"input_features\"</li>\n",
    "<li>2 hidden layers of size \"size_hidden_layer_1 & 2\"</li>\n",
    "<li>1 output layer of size 10 (as we want to predict number from 0 to 9)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_features = 28*28\n",
    "size_hidden_layer_1 = 300\n",
    "size_hidden_layer_2 = 100\n",
    "size_output_layer = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create placeholder of the input and the known target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation Graph\n",
    "X = tf.placeholder(tf.float32, shape=(None, input_features), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation layers\n",
    "hidden_layer_1 = tf.layers.dense(X, size_hidden_layer_1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "bn1 = tf.layers.batch_normalization(hidden_layer_1, training=True, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden_layer_2 = tf.layers.dense(bn1_act, size_hidden_layer_2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "bn2 = tf.layers.batch_normalization(hidden_layer_2, training=True, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "output_layer = tf.layers.dense(bn2_act, size_output_layer, name=\"output\") # pas d'activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now during the training, we will have to compute the cross entropy between the evaluated output and the real output. The objective during the training is to reduce this entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output_layer)\n",
    "loss= tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the error so we can backpropagate the error in the network to tune weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "LR = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add in the graph a node to compute the accuracy based on output from the network and the expected output. This will be used in the test set to evaluate the graph on unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "correct = tf.nn.in_top_k(output_layer, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is set, we can initialise it and create a Saver to be able to explore result in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the result presented below, I changed the name of the save based on network topology and activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorborad info\n",
    "acc_summary = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "file_writter = tf.summary.FileWriter(\"/saves/summary/BN_elu-{}-{}/\".format(size_hidden_layer_1, size_hidden_layer_2), tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can prepare the training steps. If you want to try to reduce dimensions, a PCA is set up to reduce it to the expected \"input_features\" size. This will be tested to check the gain of time and the loss of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/train-images-idx3-ubyte.gz\n",
      "Extracting /data/train-labels-idx1-ubyte.gz\n",
      "Extracting /data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "training_step = True\n",
    "mnist = input_data.read_data_sets(\"/data/\")\n",
    "n_epoch = 60\n",
    "batch_size = 70\n",
    "training_instances = mnist.train.num_examples\n",
    "nb_batch = training_instances // batch_size\n",
    "\n",
    "if input_features < 28*28:\n",
    "    pca = PCA(n_components=input_features)\n",
    "    X_train = pca.fit_transform(mnist.train.images)\n",
    "    X_test = pca.transform(mnist.test.images)\n",
    "else:\n",
    "    X_train = mnist.train.images\n",
    "    X_test = mnist.test.images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And launch the training (By changing training step to False, the model will load the latest model saved and you can only test it with datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    if not training_step:\n",
    "        saver.restore(sess, \"/saves/my_model_chapter10_2.ckpt\")\n",
    "        print(accuracy.eval(feed_dict={X: X_test, y: mnist.test.labels}))\n",
    "    else:\n",
    "        init.run()\n",
    "        for epoch in range(n_epoch):\n",
    "            for X_batch, y_batch in next_batch(X_train, mnist.train.labels, batch_size, nb_batch):\n",
    "                sess.run(optimizer, feed_dict={X: X_batch, y: y_batch})\n",
    "            accuracy_str = acc_summary.eval(feed_dict={X: X_test, y: mnist.test.labels})\n",
    "            file_writter.add_summary(accuracy_str, epoch)\n",
    "            print(epoch, accuracy.eval(feed_dict={X: X_test, y: mnist.test.labels}))\n",
    "        save_path = saver.save(sess, \"/saves/my_model_chapter10_2.ckpt\")\n",
    "    file_writter.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
