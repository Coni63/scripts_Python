{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "<a href=\"http://exercices.openclassrooms.com/assessment/627\" target=\"_target\">Lien à l'exercice</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"winequality-white.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6   \n",
      "\n",
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
      "mean        6.854788          0.278241     0.334192        6.391415   \n",
      "std         0.843868          0.100795     0.121020        5.072058   \n",
      "min         3.800000          0.080000     0.000000        0.600000   \n",
      "25%         6.300000          0.210000     0.270000        1.700000   \n",
      "50%         6.800000          0.260000     0.320000        5.200000   \n",
      "75%         7.300000          0.320000     0.390000        9.900000   \n",
      "max        14.200000          1.100000     1.660000       65.800000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
      "mean      0.045772            35.308085            138.360657     0.994027   \n",
      "std       0.021848            17.007137             42.498065     0.002991   \n",
      "min       0.009000             2.000000              9.000000     0.987110   \n",
      "25%       0.036000            23.000000            108.000000     0.991723   \n",
      "50%       0.043000            34.000000            134.000000     0.993740   \n",
      "75%       0.050000            46.000000            167.000000     0.996100   \n",
      "max       0.346000           289.000000            440.000000     1.038980   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
      "mean      3.188267     0.489847    10.514267     5.877909  \n",
      "std       0.151001     0.114126     1.230621     0.885639  \n",
      "min       2.720000     0.220000     8.000000     3.000000  \n",
      "25%       3.090000     0.410000     9.500000     5.000000  \n",
      "50%       3.180000     0.470000    10.400000     6.000000  \n",
      "75%       3.280000     0.550000    11.400000     6.000000  \n",
      "max       3.820000     1.080000    14.200000     9.000000   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           4898 non-null float64\n",
      "volatile acidity        4898 non-null float64\n",
      "citric acid             4898 non-null float64\n",
      "residual sugar          4898 non-null float64\n",
      "chlorides               4898 non-null float64\n",
      "free sulfur dioxide     4898 non-null float64\n",
      "total sulfur dioxide    4898 non-null float64\n",
      "density                 4898 non-null float64\n",
      "pH                      4898 non-null float64\n",
      "sulphates               4898 non-null float64\n",
      "alcohol                 4898 non-null float64\n",
      "quality                 4898 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(), \"\\n\")\n",
    "print(dataset.describe(), \"\\n\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 11)\n",
      "(4898,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[\"quality\"].as_matrix()#.reshape(-1,1)\n",
    "X = dataset.drop(\"quality\", axis=1).as_matrix()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe sur un modèle biclasse (si vous passez cette étape ce sera une classification multiclasse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y>6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on split le dataset juste pour avoir un dernier set d'evaluation à la fin et comparer les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_eval, y, y_eval = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3918, 11)\n",
      "(980, 11)\n",
      "(3918,)\n",
      "(980,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_eval.shape)\n",
    "print(y.shape)\n",
    "print(y_eval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réimplementation de la fonction de Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(X, y, nb_folds=5, random=True):\n",
    "    \"\"\"\n",
    "    Générateur retournant nb_folds batches de X et y mélangé ou non\n",
    "    \"\"\"\n",
    "    if random:\n",
    "        X, y = shuffle(X, y)            # le shuffle peut aussi etre fait manuellement avec numpy en créant une liste d'index\n",
    "    batch_size = X.shape[0]//nb_folds   # on coupe le dataset en nb_folds identique\n",
    "    y = y.reshape(-1, 1)\n",
    "    for i in range(nb_folds):\n",
    "        X_test = X[i*batch_size:(i+1)*batch_size, :]\n",
    "        y_test = y[i*batch_size:(i+1)*batch_size, :]\n",
    "        r_del = list(range(i*batch_size, (i+1)*batch_size))\n",
    "        X_train = np.delete(X, r_del, axis=0)\n",
    "        y_train = np.delete(y, r_del, axis=0)\n",
    "        yield X_test, y_test, X_train, y_train   # on retourne le batch suivant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le bloc suivant permet juste de valider le bon fonctionnement de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7020812   0.62836549]\n",
      " [ 0.24199751  0.63683185]\n",
      " [ 0.50939921  0.15070156]\n",
      " [ 0.21496935  0.99516869]\n",
      " [ 0.15495737  0.50079271]\n",
      " [ 0.81252883  0.96440052]\n",
      " [ 0.38443306  0.02504189]\n",
      " [ 0.6064766   0.29141225]\n",
      " [ 0.10712534  0.31890394]] \n",
      "\n",
      " [[ 0.86702591]\n",
      " [ 0.51797774]\n",
      " [ 0.95756725]\n",
      " [ 0.79332645]\n",
      " [ 0.75830272]\n",
      " [ 0.02261841]\n",
      " [ 0.11927703]\n",
      " [ 0.17634682]\n",
      " [ 0.5688124 ]] \n",
      "\n",
      "\n",
      "X_test (batch 0): \n",
      " [[ 0.7020812   0.62836549]\n",
      " [ 0.24199751  0.63683185]\n",
      " [ 0.50939921  0.15070156]] \n",
      "\n",
      "\n",
      "X_train (batch 0): \n",
      " [[ 0.21496935  0.99516869]\n",
      " [ 0.15495737  0.50079271]\n",
      " [ 0.81252883  0.96440052]\n",
      " [ 0.38443306  0.02504189]\n",
      " [ 0.6064766   0.29141225]\n",
      " [ 0.10712534  0.31890394]] \n",
      "\n",
      "\n",
      "X_test (batch 1): \n",
      " [[ 0.21496935  0.99516869]\n",
      " [ 0.15495737  0.50079271]\n",
      " [ 0.81252883  0.96440052]] \n",
      "\n",
      "\n",
      "X_train (batch 1): \n",
      " [[ 0.7020812   0.62836549]\n",
      " [ 0.24199751  0.63683185]\n",
      " [ 0.50939921  0.15070156]\n",
      " [ 0.38443306  0.02504189]\n",
      " [ 0.6064766   0.29141225]\n",
      " [ 0.10712534  0.31890394]] \n",
      "\n",
      "\n",
      "X_test (batch 2): \n",
      " [[ 0.38443306  0.02504189]\n",
      " [ 0.6064766   0.29141225]\n",
      " [ 0.10712534  0.31890394]] \n",
      "\n",
      "\n",
      "X_train (batch 2): \n",
      " [[ 0.7020812   0.62836549]\n",
      " [ 0.24199751  0.63683185]\n",
      " [ 0.50939921  0.15070156]\n",
      " [ 0.21496935  0.99516869]\n",
      " [ 0.15495737  0.50079271]\n",
      " [ 0.81252883  0.96440052]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(9,2)\n",
    "b = np.random.rand(9,1)\n",
    "print(a,\"\\n\\n\", b,\"\\n\\n\")\n",
    "\n",
    "folds = create_folds(X=a, y=b, nb_folds=3, random=False)\n",
    "for index, fold in enumerate(folds):\n",
    "    a_test, b_test, a_train, b_train = fold\n",
    "    print(\"X_test (batch {}): \\n\".format(index), a_test,\"\\n\\n\")\n",
    "    #print(\"y_test (batch {}): \\n\".format(index), b_test,\"\\n\\n\")\n",
    "    print(\"X_train (batch {}): \\n\".format(index), a_train,\"\\n\\n\")\n",
    "    #print(\"y_train (batch {}): \\n\".format(index), b_train,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(clf_param, X, y, nb_folds=5, random=True):\n",
    "    \"\"\"\n",
    "    Remplace la fonction cross-validation de Sklearn. Utilise uniquement le KNClassifier et une liste de nb_voisins en params\n",
    "    \"\"\"\n",
    "    best_param = 0\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for param in clf_param:\n",
    "        classifieur = KNeighborsClassifier(n_neighbors=param)\n",
    "        folds = create_folds(X=X, y=y, nb_folds=nb_folds, random=random)\n",
    "        total_acc_manu = 0\n",
    "        total_acc_sklearn = 0\n",
    "        for X_test, y_test, X_train, y_train in folds:\n",
    "            cloned_clf = clone(classifieur)\n",
    "            cloned_clf.fit(X_train, y_train.ravel())                                # on fit sur les n-1 folds\n",
    "            y_pred = cloned_clf.predict(X_test)                                     # on predit le dernier fold\n",
    "            total_acc_manu += sum(y_pred == y_test.ravel())/len(y_pred)             # reimplemantation de accuracy      \n",
    "            total_acc_sklearn += accuracy_score(y_test, y_pred)                     # fonction accuracy de sklearn\n",
    "        print(\"param : {}\\taccuracy manu: {:.5f} - accuracy sklearn : {:.5f}\".\\\n",
    "              format(param, total_acc_manu/nb_folds, total_acc_sklearn/nb_folds))   # moyenne d'accuracy sur le test set\n",
    "        if total_acc_sklearn > best_acc:\n",
    "            best_acc = total_acc_sklearn\n",
    "            best_param = param\n",
    "            best_model = clone(cloned_clf)\n",
    "    print(\"\\nLe meilleur paramètre est  : {} avec une accuracy moyenne de {}\".format(best_param, best_acc/nb_folds))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila le modèle est recrée. Seul bémol, le classifieur est crée dans le cross validation et on ne peut passer qu'un seul paramètre. Je n'ai pas implémenter de fonction permettant de tester toutes les combinaisons possible si on envoi n paramètre comme implémenté dans sklearn. De plus, dans sklearn, on envoie le classifieur de notre choix avec n sets de k paramètres à tester. Cependant cela complexifie le code et il faut verifier que chaque attribut appartient au classifieur etc... Pour ce TP, je n'ai pas pris ca en compte, l'objectif etant juste de recréer la cross validation et comparer les resultat avec et sans shuffle du dataset.\n",
    "\n",
    "## Validation sans randomisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param : 3\taccuracy manu: 0.81113 - accuracy sklearn : 0.81113\n",
      "param : 5\taccuracy manu: 0.81240 - accuracy sklearn : 0.81240\n",
      "param : 7\taccuracy manu: 0.82006 - accuracy sklearn : 0.82006\n",
      "param : 9\taccuracy manu: 0.81521 - accuracy sklearn : 0.81521\n",
      "param : 11\taccuracy manu: 0.81317 - accuracy sklearn : 0.81317\n",
      "param : 13\taccuracy manu: 0.81266 - accuracy sklearn : 0.81266\n",
      "param : 15\taccuracy manu: 0.81572 - accuracy sklearn : 0.81572\n",
      "\n",
      "Le meilleur paramètre est  : 7 avec une accuracy moyenne de 0.8200612557427259\n"
     ]
    }
   ],
   "source": [
    "best_model = cross_validation([3, 5, 7, 9, 11, 13, 15], X, y, nb_folds=3, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814285714286\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X, y)\n",
    "print(best_model.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation avec randomisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param : 3\taccuracy manu: 0.82338 - accuracy sklearn : 0.82338\n",
      "param : 5\taccuracy manu: 0.81700 - accuracy sklearn : 0.81700\n",
      "param : 7\taccuracy manu: 0.81879 - accuracy sklearn : 0.81879\n",
      "param : 9\taccuracy manu: 0.81496 - accuracy sklearn : 0.81496\n",
      "param : 11\taccuracy manu: 0.81317 - accuracy sklearn : 0.81317\n",
      "param : 13\taccuracy manu: 0.81394 - accuracy sklearn : 0.81394\n",
      "param : 15\taccuracy manu: 0.82338 - accuracy sklearn : 0.82338\n",
      "\n",
      "Le meilleur paramètre est  : 3 avec une accuracy moyenne de 0.8233792751403778\n"
     ]
    }
   ],
   "source": [
    "best_model2 = cross_validation([3, 5, 7, 9, 11, 13, 15], X, y, nb_folds=3, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823469387755\n"
     ]
    }
   ],
   "source": [
    "best_model2.fit(X, y)\n",
    "print(best_model2.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison au GridSearch de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid, cv=3, scoring=\"accuracy\")\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81189 (+/-0.013) - {'n_neighbors': 3}\n",
      "0.81240 (+/-0.014) - {'n_neighbors': 5}\n",
      "0.82032 (+/-0.010) - {'n_neighbors': 7}\n",
      "0.81572 (+/-0.001) - {'n_neighbors': 9}\n",
      "0.81215 (+/-0.002) - {'n_neighbors': 11}\n",
      "0.81266 (+/-0.005) - {'n_neighbors': 13}\n",
      "0.81598 (+/-0.004) - {'n_neighbors': 15}\n",
      "\n",
      "Le meilleur paramètre est  : 7 avec une accuracy moyenne de 0.8203164880040837\n"
     ]
    }
   ],
   "source": [
    "evaluation = grid_search.cv_results_\n",
    "for score, dev, param in zip(evaluation[\"mean_test_score\"], evaluation[\"std_test_score\"],evaluation[\"params\"]):  # on veut la moyenne d'accuracy sur le test set pour chaque param\n",
    "    print(\"{:.5f} (+/-{:.3f}) - {}\".format(score, dev, param))\n",
    "print(\"\\nLe meilleur paramètre est  : {} avec une accuracy moyenne de {}\".format(grid_search.best_params_[\"n_neighbors\"] , grid_search.best_score_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814285714286\n"
     ]
    }
   ],
   "source": [
    "best_model3 = grid_search.best_estimator_\n",
    "best_model3.fit(X, y)\n",
    "print(best_model3.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "La fonction de Cross-Validation a bien été réimplémenté. Elle permet ou non de melanger le dataset. Cependant le dataset etant deja mélangé, il n'y a pas de gain particulier a re-melanger le dataset (cf bloc 12 vs bloc 14). On remarque meme une baisse de l'accuracy en moyenne avec le mélange. Cependant la meilleur accuracy reste atteinte en mélangeant le dataset (0.8214 vs 0.8183).\n",
    "\n",
    "On remarque aussi que le modèle sans shuffle et la crossvalidation de scikit learn sont très similaires et donne le meme \"meilleur\" paramètre (paramètre différent si on mélange le dataset).\n",
    "\n",
    "NB : J'ai utiliser 3 folds pour cette classification (ca peut biensur etre changé à souhait). Cependant, il faut eviter d'aller au dela de 5 folds si vous gardez le dataset multiclasse car il se peut que des folds ne contienne aucun element d'une classe. Cela fausse le resultat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
